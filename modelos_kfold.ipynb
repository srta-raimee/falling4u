{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuINKCmM-CZD"
      },
      "source": [
        "# Links\n",
        "- [Drive Artigos](https://drive.google.com/drive/folders/1R9LVdajgDMxF-zba9aMeEOeSs8wfhzU6?hl=pt-br)\n",
        "- [Google Notebook LLM](https://notebooklm.google.com/notebook/8c75ea8a-3ce1-4cfd-bbc5-9819d95599e1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMbupS_IyKbi"
      },
      "source": [
        "# Larissa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNo2cv7K1Zr-"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import csv\n",
        "import shutil\n",
        "import numpy as np\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j7gjltQwULj",
        "outputId": "ef6a2019-2d5b-4c72-c344-09be0a80e9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "4\n",
            "NVIDIA H100 80GB HBM3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aUtGr2cfbu00"
      },
      "outputs": [],
      "source": [
        "\n",
        "# le2i = \"/content/drive/MyDrive/TCC2/le2i\" #videos\n",
        "# URFD = \"/content/drive/MyDrive/TCC2/URFD\" # imgs\n",
        "fall = \"/fall_dataset\" #imgs YOLO labeled\n",
        "\n",
        "# listar arquivos da pasta\n",
        "# os.listdir(le2i)\n",
        "# os.listdir(URFD)\n",
        "# os.listdir(fall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3JKarjrsTQN"
      },
      "source": [
        "##Usando Fall Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "2XE_yU2ipZie",
        "outputId": "e0fa4be8-ea14-4d55-c1c9-f3cfefc0d392"
      },
      "outputs": [],
      "source": [
        "# funcoes para rodar experimentos \n",
        "\n",
        "def format_time(seconds):\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return f\"{int(hours):02d}h {int(minutes):02d}m {seconds:.2f}s\"\n",
        "\n",
        "def run_kfold_training(kfold_base_dir, output_csv, k_folds=5, epochs=100, batch_size=8, model_name=\"yolo11n.pt\"):\n",
        "    CSV_RESULTS_FILE = output_csv\n",
        "    K_FOLDS = k_folds\n",
        "    EPOCHS = epochs\n",
        "    BATCH_SIZE = batch_size\n",
        "    NOME_MODELO_INICIAL = model_name\n",
        "    EXPERIMENT_PREFIX = f'kfold_{os.path.basename(kfold_base_dir)}_{k_folds}folds'\n",
        "\n",
        "    all_fold_metrics = []\n",
        "    total_start_time = time.perf_counter()\n",
        "\n",
        "    for fold_num in range(1, K_FOLDS + 1):\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"INICIANDO TREINAMENTO DO FOLD {fold_num}/{K_FOLDS}\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        fold_dir = os.path.join(kfold_base_dir, f\"fold_{fold_num}\")\n",
        "        \n",
        "        yaml_path = os.path.join(fold_dir, 'data.yaml')\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            f.write(f\"path: {os.path.abspath(fold_dir)}\\n\")\n",
        "            f.write(\"train: images/train\\n\")\n",
        "            f.write(\"val: images/val\\n\")\n",
        "            f.write(\"nc: 2\\n\")\n",
        "            f.write(\"names: ['fall', 'not fall']\\n\")\n",
        "        \n",
        "        model = YOLO(NOME_MODELO_INICIAL)\n",
        "        \n",
        "        fold_experiment_name = f\"{EXPERIMENT_PREFIX}_fold_{fold_num}\"\n",
        "        model.train(data=yaml_path, epochs=EPOCHS, batch=BATCH_SIZE, device=0, name=fold_experiment_name)\n",
        "        \n",
        "        best_model = YOLO(f'runs/detect/{fold_experiment_name}/weights/best.pt')\n",
        "        results = best_model.val()\n",
        "\n",
        "        fold_metrics = {\n",
        "            'mAP50_95': results.box.map, 'mAP50': results.box.map50,\n",
        "            'precision': results.box.mp, 'recall': results.box.mr\n",
        "        }\n",
        "        all_fold_metrics.append(fold_metrics)\n",
        "        print(f\"Métricas do Fold {fold_num}: {fold_metrics}\")\n",
        "        \n",
        "    total_end_time = time.perf_counter()\n",
        "    total_duration_str = format_time(total_end_time - total_start_time)\n",
        "\n",
        "    avg_metrics = {\n",
        "        'avg_mAP50_95': np.mean([m['mAP50_95'] for m in all_fold_metrics]),\n",
        "        'std_mAP50_95': np.std([m['mAP50_95'] for m in all_fold_metrics]),\n",
        "        'avg_mAP50': np.mean([m['mAP50'] for m in all_fold_metrics]),\n",
        "        'std_mAP50': np.std([m['mAP50'] for m in all_fold_metrics]),\n",
        "        'avg_precision': np.mean([m['precision'] for m in all_fold_metrics]),\n",
        "        'std_precision': np.std([m['precision'] for m in all_fold_metrics]),\n",
        "        'avg_recall': np.mean([m['recall'] for m in all_fold_metrics]),\n",
        "        'std_recall': np.std([m['recall'] for m in all_fold_metrics]),\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESULTADO FINAL DO K-FOLD CROSS-VALIDATION\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Tempo Total de Execução: {total_duration_str}\")\n",
        "    print(f\"Métricas (Média ± Desvio Padrão) calculadas com {K_FOLDS} folds:\")\n",
        "    print(f\"mAP50-95: {avg_metrics['avg_mAP50_95']:.4f} ± {avg_metrics['std_mAP50_95']:.4f}\")\n",
        "    print(f\"mAP50:    {avg_metrics['avg_mAP50']:.4f} ± {avg_metrics['std_mAP50']:.4f}\")\n",
        "    print(f\"Precisão: {avg_metrics['avg_precision']:.4f} ± {avg_metrics['std_precision']:.4f}\")\n",
        "    print(f\"Recall:   {avg_metrics['avg_recall']:.4f} ± {avg_metrics['std_recall']:.4f}\")\n",
        "\n",
        "    header = ['experimento_base', 'k_folds', 'tempo_total', 'avg_mAP50_95', 'std_mAP50_95', 'avg_mAP50', 'std_mAP50', 'avg_precision', 'std_precision', 'avg_recall', 'std_recall']\n",
        "    data_row = [\n",
        "        EXPERIMENT_PREFIX, K_FOLDS, total_duration_str,\n",
        "        f\"{avg_metrics['avg_mAP50_95']:.4f}\", f\"{avg_metrics['std_mAP50_95']:.4f}\",\n",
        "        f\"{avg_metrics['avg_mAP50']:.4f}\", f\"{avg_metrics['std_mAP50']:.4f}\",\n",
        "        f\"{avg_metrics['avg_precision']:.4f}\", f\"{avg_metrics['std_precision']:.4f}\",\n",
        "        f\"{avg_metrics['avg_recall']:.4f}\", f\"{avg_metrics['std_recall']:.4f}\"\n",
        "    ]\n",
        "\n",
        "    file_exists = os.path.isfile(CSV_RESULTS_FILE)\n",
        "    with open(CSV_RESULTS_FILE, 'a', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        if not file_exists:\n",
        "            writer.writerow(header)\n",
        "        writer.writerow(data_row)\n",
        "    \n",
        "    print(f\"\\nResultados médios salvos em '{CSV_RESULTS_FILE}'\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    LISTA_DE_FOLDS = [5, 10, 15, 20]\n",
        "    OUTPUT_CSV_FILE = 'resultados_kfold.csv'\n",
        "    NUM_EPOCHS = 100\n",
        "    BATCH_SIZE = 8\n",
        "    MODELO = \"yolo11n.pt\"\n",
        "\n",
        "    for k in LISTA_DE_FOLDS:\n",
        "        kfold_data_dir = f'kfold_dataset_{k}'\n",
        "        \n",
        "        print(f\"\\n================ INICIANDO EXPERIMENTO PARA K={k}, Lendo da pasta: {kfold_data_dir} ================\")\n",
        "        \n",
        "        run_kfold_training(\n",
        "            kfold_base_dir=kfold_data_dir,\n",
        "            output_csv=OUTPUT_CSV_FILE,\n",
        "            k_folds=k,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            model_name=MODELO\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pseudo-tcc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
